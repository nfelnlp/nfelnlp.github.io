---
layout: single
classes: wide
author_profile: true
title: "Open Topics"
---

<!-- DeLoreason -->
**Explaining Knowledge Conflicts and Factual Errors (of Temporal Generalization) in LLM Generations**  
How can we expose and express knowledge conflicts in LLMs resulting from poor temporal generalization?  
<p style="font-size:smaller;">
[1] <a href="https://arxiv.org/abs/2407.17023">DYNAMICQA (MarjanoviÄ‡ et al., EMNLP 2024 Findings)</a><br>
[2] <a href="http://arxiv.org/abs/2310.05189">Survey on Factuality Challenges (Augenstein et al., 2023)</a><br>
[3] <a href="https://openreview.net/forum?id=bzs4uPLXvi">Unfaithful Explanations in CoT Prompting (Turpin et al., NeurIPS 2023)</a><br>
[4] <a href="https://aclanthology.org/2023.emnlp-main.751/">Interventions for Explaining Factual Associations (Geva et al., EMNLP 2023)</a><br>
[5] <a href="https://arxiv.org/abs/2402.11436">Self-Bias in LLMs (Xu et al., 2024)</a><br>
[6] <a href="https://aclanthology.org/2024.findings-acl.441">Mismatches between Token Probabilities and LLM Outputs (Wang et al., ACL 2024 Findings)</a><br>
[7] <a href="http://arxiv.org/abs/2310.00935">Resolving Knowledge Conflicts (Wang et al., COLM 2024)</a><br>
[8] <a href="https://openreview.net/forum?id=gfFVATffPd">SAT Probe (Yuksekgonul et al., ICLR 2024)</a><br>
[9] <a href="https://aclanthology.org/2024.naacl-long.46/">MONITOR metric (Wang et al., NAACL 2024)</a>
</p><br>

<!-- InquAIrer -->
**Conversational Model Refinement**  
1. Can we elicit expert human feedback using targeted question generation in a mixed-initiative dialogue setting?
2. Can we use human feedback to natural language explanations to improve the model performance and align it to user preferences?
<p style="font-size:smaller;">
[1] <a href="https://arxiv.org/abs/2103.10415">Compositional Explanations (Yao et al., NeurIPS 2021)</a><br>
[2] <a href="https://aclanthology.org/2024.acl-long.302/">Digital Socrates (Gu et al., ACL 2024)</a><br>
[3] <a href="https://aclanthology.org/2024.naacl-long.168/">Explanation Formats (Malaviya et al., NAACL 2024)</a><br>
[4] <a href="https://aclanthology.org/2022.findings-acl.75/">FeedbackQA (Li et al., ACL 2022 Findings)</a><br>
[5] <a href="https://aclanthology.org/2023.findings-emnlp.791/">Synthesis Step by Step (Wang et al., EMNLP 2023 Findings)</a>
</p><br>

---

[*Topics Archive*](./supervision/topics_archive.md)
