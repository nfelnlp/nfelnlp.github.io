---
layout: single
classes: wide
author_profile: true
title: "Open Topics"
---

If you are a **Bachelor's or Master's student at TU Berlin** and interested in writing your thesis on one of the following topics, please contact me via mail (see sidebar).  
You should have a **solid background** in and have taken prior courses related to **natural language processing** and/or **machine learning**.  
At the moment, I'm not in the position of supervising PhD students on my own, but I'm always happy to provide consultation on an informal basis!

**2025-09-01**: I'm currently at full capacity regarding supervisions and will be open to new inquiries in <u>December 2025</u>.

---

**Verbalization of layer functions**
Translating layer analyses "globally" (across a whole dataset) and "locally" (for single instances) into natural language
<p style="font-size:smaller;">
[1] <a href="https://aclanthology.org/2025.acl-long.866/">MAPS (Elhelo & Geva, ACL 2025)</a><br>
[2] <a href="https://arxiv.org/abs/2506.15538">PRISM (Kopf et al., NeurIPS 2025)</a><br>
[3] <a href="https://arxiv.org/abs/2412.08686">LatentQA (Pan et al., 2024)</a><br>
[4] <a href="https://openreview.net/forum?id=LUsx0chTsL">Talking Heads (Merullo et al., NeurIPS 2024)</a><br>
[5] <a href="https://openreview.net/forum?id=VDWdnaM0Gt">Hou & Castanon (ICML 2023)</a><br>
[6] <a href="https://aclanthology.org/2024.emnlp-main.847/">Layer by Layer (Zhao et al., EMNLP 2024)</a><br>
[7] <a href="https://aclanthology.org/2024.emnlp-main.965/">Information Flow Routes (Ferrando & Voita, EMNLP 2024)</a><br>
[8] <a href="https://openreview.net/forum?id=oP3b5YBFoP">Ikeda et al. (COLM 2025)</a><br>
</p><br>

**Contrastive attribution for readability-controlled generation**
<p style="font-size:smaller;">
[1] <a href="https://aclanthology.org/2025.gem-1.11/">Hsu et al. (GEM @ ACL 2025)</a><br>
[2] <a href="https://aclanthology.org/2022.emnlp-main.14/">Yin & Neubig (EMNLP 2022)</a><br>
[3] <a href="https://doi.org/10.1162/tacl_a_00653">Agrawal & Carpuat (TACL 2024)</a><br>
[4] <a href="https://aclanthology.org/2025.coling-main.452/">Barayan et al. (COLING 2025)</a><br>
[5] <a href="https://dl.acm.org/doi/10.1145/3706598.3713229">Bu√ßinca et al. (CHI 2025)</a><br>
[6] <a href="https://aclanthology.org/2024.emnlp-main.318/">RSA-Control (Wang & Demberg, EMNLP 2024)</a><br>
</p><br>

**Agentic auto-intepretability**
Designing LLM agents with self-testing and self-interpretability tools to write model evaluation reports
<p style="font-size:smaller;">
[1] <a href="https://dl.acm.org/doi/10.5555/3692070.3693872">MAIA (Shaham et al., ICML 2024)</a><br>
[2] <a href="https://openreview.net/forum?id=Sx038qxjek">CRITIC (Gou et al., ICLR 2024)</a><br>
[3] <a href="https://aclanthology.org/2024.naacl-long.110/">Liu et al. (NAACL 2024)</a><br>
[4] <a href="https://arxiv.org/abs/2506.12152">Kim et al. (2025)</a><br>
[5] <a href="https://arxiv.org/abs/2405.00208">Ferrando et al. (2024)</a><br>
</p><br>

**Measuring the influence of verbatim-memorized content in training data on prompting**
<p style="font-size:smaller;">
[1] <a href="https://aclanthology.org/2024.emnlp-main.598/">Huang et al. (EMNLP 2024)</a><br>
[2] <a href="https://openreview.net/forum?id=TatRHT_1cK">Carlini et al. (ICLR 2023)</a><br>
[3] <a href="https://aclanthology.org/2024.findings-emnlp.212/">Prabhakar et al. (EMNLP 2024 Findings)</a><br>
[4] <a href="https://arxiv.org/abs/2508.02037">STIM (Li, Chen et al., 2025)</a><br>
[5] <a href="https://arxiv.org/abs/2507.04782">Reason to Rote (Du et al., EMNLP 2025)</a><br>
[6] <a href="https://arxiv.org/abs/2505.24832">Morris et al. (2025)</a><br>
[7] <a href="https://openreview.net/forum?id=Uic3ojVhXh">ParaPO (Chen et al., COLM 2025)</a><br>
[8] <a href="https://arxiv.org/abs/2507.05578">Survey on Memorization (Xiong et al., 2025)</a><br>
</p><br>

**Estimating the influence of LLM sycophancy on user interactions**
<p style="font-size:smaller;">
[1] <a href="https://arxiv.org/abs/2505.13995">ELEPHANT (Cheng et al., 2025)</a><br>
[2] <a href="https://aclanthology.org/2024.acl-long.858/">Farm (Xu et al., 2024)</a><br>
[3] <a href="https://arxiv.org/abs/2509.10830">The Siren Song of LLMs (Shi et al., 2025)</a><br>
[4] <a href="https://openreview.net/forum?id=Orvjm9UqH2">Epistemic Alignment (Clark et al., COLM 2025)</a><br>
[5] <a href="https://arxiv.org/abs/2409.12809">Don't Be Fooled (Spitzer et al., 2024)</a><br>
[6] <a href="https://openreview.net/forum?id=MzM99vV5Rx">IQA-EVAL (Li et al., NeurIPS 2024)</a><br>
</p><br>

**Text simplification of medical terminology**  
<p style="font-size:smaller;">
[1] <a href="https://aclanthology.org/2024.acl-long.459/">FactPICO (Joseph et al., ACL 2024)</a><br>
[2] <a href="https://aclanthology.org/2024.findings-emnlp.737/">README (Yao et al., EMNLP 2024 Findings)</a><br>
[3] <a href="https://aclanthology.org/2024.findings-acl.279/">Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification (Yang et al., ACL 2024 Findings)</a><br>
[4] <a href="https://arxiv.org/abs/2406.15963">Effectiveness of ChatGPT in explaining complex medical reports to patients (Sun et al., 2024)</a><br>
[5] <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2815868">Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format (Zaretsky et al., JAMA 2024)</a><br>
[6] <a href="https://aclanthology.org/2024.emnlp-main.1051/">Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting (Kayser et al., EMNLP 2024)</a>
</p><br>

**Component analyses for biomedical tasks**
<p style="font-size:smaller;">
[1] <a href="https://www.nature.com/articles/s41586-023-06291-2">Large language models encode clinical knowledge (Singhal et al., Nature 2023)</a><br>
[2] <a href="https://proceedings.mlr.press/v259/wu25a.html">DILA: Dictionary Label Attention for Mechanistic Interpretability in High-dimensional Multi-label Medical Coding Prediction (Wu et al., PMLR 2025)</a><br>
[3] <a href="https://arxiv.org/abs/2502.13319">Elucidating Mechanisms of Demographic Bias in LLMs for Healthcare (Ahsan et al., 2025)</a>
</p><br>


---

[*Topics Archive*](./topics_archive.md)
