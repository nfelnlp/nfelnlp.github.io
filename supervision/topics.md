---
layout: single
classes: wide
author_profile: true
title: "Open Topics"
---

If you are a **Bachelor's or Master's student at TU Berlin** and interested in writing your thesis on one of the following topics, please contact me via mail (see sidebar).  
You should have a **solid background** in and have taken prior courses related to **natural language processing** and/or **machine learning**.

---


**Text Simplification of Medical Terminology**  
<p style="font-size:smaller;">
[1] <a href="https://aclanthology.org/2024.acl-long.459/">FactPICO (Joseph et al., ACL 2024)</a><br>
[2] <a href="https://aclanthology.org/2024.findings-emnlp.737/">README (Yao et al., EMNLP 2024 Findings)</a><br>
[3] <a href="https://aclanthology.org/2024.findings-acl.279/">Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification (Yang et al., ACL 2024 Findings)</a><br>
[4] <a href="https://arxiv.org/abs/2406.15963">Effectiveness of ChatGPT in explaining complex medical reports to patients (Sun et al., 2024)</a><br>
[5] <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2815868">Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format (Zaretsky et al., JAMA 2024)</a><br>
[6] <a href="https://aclanthology.org/2024.emnlp-main.1051/">Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting (Kayser et al., EMNLP 2024)</a>
</p><br>

**Component Analyses for Biomedical Tasks**
<p style="font-size:smaller;">
[1] <a href="https://www.nature.com/articles/s41586-023-06291-2">Large language models encode clinical knowledge (Singhal et al., Nature 2023)</a><br>
[2] <a href="https://proceedings.mlr.press/v259/wu25a.html">DILA: Dictionary Label Attention for Mechanistic Interpretability in High-dimensional Multi-label Medical Coding Prediction (Wu et al., PMLR 2025)</a><br>
[3] <a href="https://arxiv.org/abs/2502.13319">Elucidating Mechanisms of Demographic Bias in LLMs for Healthcare (Ahsan et al., 2025)</a>
</p><br>

<!-- DeLoreason -->
**Explaining Knowledge Conflicts and Factual Errors (of Temporal Generalization) in LLM Generations**  
How can we expose and express knowledge conflicts in LLMs resulting from poor temporal generalization?  
<p style="font-size:smaller;">
[1] <a href="https://aclanthology.org/2024.findings-emnlp.838/">DYNAMICQA (MarjanoviÄ‡ et al., EMNLP 2024 Findings)</a><br>
[2] <a href="https://arxiv.org/abs/2310.05189">Survey on Factuality Challenges (Augenstein et al., Nature Machine Intelligence 2024)</a><br>
[3] <a href="https://openreview.net/forum?id=bzs4uPLXvi">Unfaithful Explanations in CoT Prompting (Turpin et al., NeurIPS 2023)</a><br>
[4] <a href="https://aclanthology.org/2023.emnlp-main.751/">Interventions for Explaining Factual Associations (Geva et al., EMNLP 2023)</a><br>
[5] <a href="https://aclanthology.org/2024.acl-long.826/">Self-Bias in LLMs (Xu et al., ACL 2024)</a><br>
[6] <a href="https://aclanthology.org/2024.findings-acl.441">Mismatches between Token Probabilities and LLM Outputs (Wang et al., ACL 2024 Findings)</a><br>
[7] <a href="https://openreview.net/forum?id=ptvV5HGTNN">Resolving Knowledge Conflicts (Wang et al., COLM 2024)</a><br>
[8] <a href="https://openreview.net/forum?id=gfFVATffPd">SAT Probe (Yuksekgonul et al., ICLR 2024)</a><br>
[9] <a href="https://aclanthology.org/2024.naacl-long.46/">MONITOR metric (Wang et al., NAACL 2024)</a>
</p><br>



---

[*Topics Archive*](./topics_archive.md)
