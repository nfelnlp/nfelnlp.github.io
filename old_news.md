---
layout: single
classes: wide
author_profile: true
---

2023-05-30 : [Saliency Map Verbalization](./publications/index.md#2023) (first-author paper) accepted to ACL 2023! See you in Toronto! üçÅ  
2023-05-19 : [Inseq](./publications/index.md#2023) accepted to ACL 2023! [MultiTACRED](https://aclanthology.org/2023.acl-long.210/) which I reviewed for my colleagues has been accepted as well.  
2023-02-27 : Inseq pre-print published on arXiv.  
2022-12-26 : Three papers accepted to ESSV and HUCAPP. New interpretability library Inseq (project led by Gabriele Sarti) now available on GitHub.  
2022-11-21 : Journal paper about "Interactive Explainable AI" accepted to KI.  
2022-10-14 : First-author paper on "Saliency Map Verbalization" is now on [arXiv](https://arxiv.org/abs/2210.07222).  
2022-10-13 : One paper I reviewed for my colleagues was accepted to the [EMNLP 2022](https://github.com/DFKI-NLP/meffi-prompt) main track.  
2022-07-04 : Companion paper to "Personalized Conversational Agents" accepted to SIGDIAL 2022.  
2022-06-15 : Paper on "Personalized Conversational Agents" accepted to INTERSPEECH 2022.  
2022-06-14 : "Mediators" is now available on arXiv.  
2022-06-04 : First-author paper "Mediators: Conversational Agents Explaining Language Model Behavior" accepted to the IJCAI-ECAI 2022 Workshop on XAI.  
2022-04-04 : Paper on "Textual Explanations for Clinical Decision Support" accepted to LREC as a poster.  
2022-03-31 : Two papers I reviewed for my colleagues were accepted to the NLP-Power! and Repl4NLP workshops at [ACL 2022](https://dfki-nlp.github.io/post/acl2022/)  
2022-03-22 : [Project report](https://graphite.page/explainable-ai-report/) on "XAI and meaningful information in automated decision-making" now available in full.  
