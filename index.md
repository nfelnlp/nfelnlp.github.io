<img src="https://raw.githubusercontent.com/nfelnlp/nfelnlp.github.io/main/figures/avatar.jpg?raw=true" width="200px" align="right">  

# Welcome üëã
Welcome to my homepage! I am Nils Feldhus and am currently working on my PhD thesis in explainable natural language processing at the [German Research Center for Artificial Intelligence](https://www.dfki.de/en/web/research/research-departments/speech-and-language-technology) and the [Technische Universit√§t Berlin](https://www.tu.berlin/en/) under the supervision of [Sebastian M√∂ller](https://www.qu.tu-berlin.de/menue/team/professur/parameter/en/).

# Research interests üëÄ
My main research interest is making (neural) language models more interpretable by building applications that democratize access to explanations. Topics of interest are rationale generation, data-centric interpretability, information-seeking dialogue, and evaluation measures for generated text.  

# News ü§©
2023-11-13 : InterroLang will be presented as an in-person poster at BlackboxNLP (Thu, Dec 7, 11:00 AM) and Findings (Sat, Dec 9, 09:00 AM).  
2023-11-03 : Invited talk at [Human-Centric AI group of NEC Labs Europe, Heidelberg](https://www.neclab.eu/research-areas/data-science/human-centric-ai)  
2023-10-08 : "InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations" accepted to EMNLP 2023 Findings! ü¶Å This is my fourth first-author paper and an implementation of the Mediators precursor paper.  
2023-05-30 : [Saliency Map Verbalization](https://arxiv.org/abs/2210.07222) (first-author paper) accepted to ACL 2023! See you in Toronto! üçÅ  
2023-05-19 : [Inseq](https://gsarti.com/project/inseq/) accepted to ACL 2023!   [MultiTACRED](https://arxiv.org/abs/2305.04582) which I reviewed for my colleagues has been accepted as well.  
2023-02-27 : Inseq pre-print published on arXiv.  
2022-12-26 : Three papers accepted to ESSV and HUCAPP. New interpretability library Inseq (project led by Gabriele Sarti) now available on GitHub.  
2022-11-21 : Journal paper about "Interactive Explainable AI" accepted to KI.  
2022-10-14 : First-author paper on "Saliency Map Verbalization" is now on [arXiv](https://arxiv.org/abs/2210.07222).  
2022-10-13 : One paper I reviewed for my colleagues was accepted to the [EMNLP 2022](https://github.com/DFKI-NLP/meffi-prompt) main track.  
2022-07-04 : Companion paper to "Personalized Conversational Agents" accepted to SIGDIAL 2022.  
2022-06-15 : Paper on "Personalized Conversational Agents" accepted to INTERSPEECH 2022.  
2022-06-14 : "Mediators" is now available on arXiv.  
2022-06-04 : First-author paper "Mediators: Conversational Agents Explaining Language Model Behavior" accepted to the IJCAI-ECAI 2022 Workshop on XAI.  
2022-04-04 : Paper on "Textual Explanations for Clinical Decision Support" accepted to LREC as a poster.  
2022-03-31 : Two papers I reviewed for my colleagues were accepted to the NLP-Power! and Repl4NLP workshops at [ACL 2022](https://dfki-nlp.github.io/post/acl2022/)  
2022-03-22 : [Project report](https://graphite.page/explainable-ai-report/) on "XAI and meaningful information in automated decision-making" now available in full.  


# Publications üìö

## 2023

<img src="https://raw.githubusercontent.com/nfelnlp/nfelnlp.github.io/main/figures/InterroLang_Logo.png?raw=true" width="200px" align="right">  
### InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations  
**Nils Feldhus**, Qianli Wang, Tatiana Anikina, Sahil Chopra, Cennet Oguz and Sebastian M√∂ller  
*EMNLP 2023 Findings* & *[BlackboxNLP](https://blackboxnlp.github.io/) Workshop*  
ACL Anthology | [arXiv](https://arxiv.org/abs/2310.05592) | [GitHub](https://github.com/DFKI-NLP/InterroLang)  

<a href="https://arxiv.org/abs/2210.07222"><img src="https://raw.githubusercontent.com/nfelnlp/nfelnlp.github.io/main/figures/SMV_FontLogo.png?raw=true" width="200px" align="right"></a>  
### Saliency Map Verbalization: Comparing Feature Importance Representations from Model-free and Instruction-based Methods  
**Nils Feldhus**, Leonhard Hennig, Maximilian Dustin Nasert, Christopher Ebert, Robert Schwarzenberg and Sebastian M√∂ller  
*ACL 2023 Workshop on Natural Language Reasoning and Structured Explanations (NLRSE)*  
[ACL Anthology](https://aclanthology.org/2023.nlrse-1.4/) | [arXiv](https://arxiv.org/abs/2210.07222) | [GitHub](https://github.com/DFKI-NLP/SMV)  

<a href="https://github.com/inseq-team/inseq"><img src="https://raw.githubusercontent.com/inseq-team/inseq/main/docs/source/images/inseq_logo.png" width="200px" align="right"></a>  
### Inseq: An Interpretability Toolkit for Sequence Generation Models  
Gabriele Sarti, **Nils Feldhus**, Ludwig Sickert, Oskar van der Wal, Malvina Nissim, Arianna Bisazza  
*ACL 2023 System Demonstrations*  
[ACL Anthology](https://aclanthology.org/2023.acl-demo.40/) | [arXiv](http://arxiv.org/abs/2302.13942) | [GitHub](https://github.com/inseq-team/inseq) | [Project page](https://gsarti.com/project/inseq/)  

### Pre-trained Language Models for the Automatic Evaluation of Customer Chatbot Dialogs
Mika Rebensburg, Stefan Hillmann, **Nils Feldhus**  
*ESSV 2023*  
[Proceedings](https://www.essv.de/paper.php?id=1170)  

### Adapters for Resource-Efficient Deployment of NLU Models
Jan Nehring, Akhyar Ahmed, **Nils Feldhus**  
*ESSV 2023*  
[Proceedings](https://www.essv.de/paper.php?id=1196) | [GitHub](https://github.com/jnehring/ESSV2023-Adapters-for-Resource-Efficient-Deployment-of-NLU-models)  

### Fighting Disinformation - Overview of Recent AI-based Collaborative Human-Computer Interaction for Intelligent Decision Support Systems
Tim Polzehl, Vera Schmitt, **Nils Feldhus**, Joachim Meyer, Sebastian M√∂ller  
*HUCAPP 2023*  
[SciTePress](https://www.scitepress.org/Link.aspx?doi=10.5220/0011788900003417)  


## 2022

### XAINES: Explaining AI with Narratives
Mareike Hartmann, Han Du, **Nils Feldhus**, Ivana Kruijff-Korbayov√° and Daniel Sonntag  
*[KI - K√ºnstliche Intelligenz](https://www.springer.com/journal/13218/)*  
[Journal article on Springer](https://doi.org/10.1007/s13218-022-00780-8)  

<a href="https://arxiv.org/abs/2206.06029"><img src="https://raw.githubusercontent.com/nfelnlp/nfelnlp.github.io/main/figures/Mediators_Logo.png?raw=true" width="200px" align="right"></a>  
### Mediators: Conversational Agents Explaining NLP Model Behavior
**Nils Feldhus**, Ajay Madhavan Ravichandran and Sebastian M√∂ller  
[*IJCAI-ECAI 2022 Workshop on XAI*](https://sites.google.com/view/xai2022/)  
[arXiv](https://arxiv.org/abs/2206.06029) | <a href="{{ site.url }}/slides/Mediators_IJCAI_2022.pdf">Slides</a>  

### Towards Personality-aware Chatbots
Daniel Fernau, Stefan Hillmann, **Nils Feldhus**, Tim Polzehl and Sebastian M√∂ller  
*[SIGDIAL 2022](https://2022.sigdial.org/)*  
[ACL Anthology](https://aclanthology.org/2022.sigdial-1.15/) | [Video (Live presentation)](https://www.youtube.com/watch?v=06hrn65ypxE)  

### Towards Automated Dialog Personalization using MBTI Personality Indicators
Daniel Fernau, Stefan Hillmann, **Nils Feldhus** and Tim Polzehl  
*[INTERSPEECH 2022](http://interspeech2022.org/)*  
[ISCA Proceedings](https://doi.org/10.21437/Interspeech.2022-376)  

### A Comparison of Feature Extraction Models for Medical Image Captioning  
Sebastian Germer, Hristina Uzunova, Jan Ehrhardt, **Nils Feldhus**, Philippe Thomas and Heinz Handels  
*GMDS-TMF 2022*  
[PDF](https://access.online-registry.net/gmds2022/temp/export/exp_1665555575167_e3b7.pdf)  

### An Annotated Corpus of Textual Explanations for Clinical Decision Support
Roland Roller, Aljoscha Burchardt, **Nils Feldhus**, Laura Seiffe, Klemens Budde, Simon Ronicke and Bilgin Osmanodja  
*LREC 2022*  
[ACL Anthology](https://aclanthology.org/2022.lrec-1.248/)  

### What to explain when explaining is difficult? An interdisciplinary primer on XAI and meaningful information in automated decision-making  
Hadi Asghari, Nadine Birner, Aljoscha Burchardt, Daniela Dicks, Judith Fassbinder, **Nils Feldhus**, Freya Hewett, Vincent Hofmann, Matthias C. Kettemann, Wolfgang Schulz, Judith Simon, Jakob Stolberg-Larsen and Theresa Z√ºger  
*Project report* (published 2022-03-22)  
[Full report](https://graphite.page/explainable-ai-report/)  


## 2021

<a href="https://github.com/DFKI-NLP/thermostat"><img src="https://raw.githubusercontent.com/DFKI-NLP/thermostat/main/figures/logo.png?raw=true" width="200px" align="right"></a>  
### Thermostat: A Large Collection of NLP Model Explanations and Analysis Tools
**Nils Feldhus**, Robert Schwarzenberg and Sebastian M√∂ller  
*2021 Conference on Empirical Methods in Natural Language Processing (EMNLP): System Demonstrations*  
[ACL Anthology](https://aclanthology.org/2021.emnlp-demo.11/) | [arXiv](https://arxiv.org/abs/2108.13961) | [GitHub](https://github.com/DFKI-NLP/thermostat) | [Video](https://aclanthology.org/2021.emnlp-demo.11.mp4)

### Efficient Explanations from Empirical Explainers
Robert Schwarzenberg, **Nils Feldhus** and Sebastian M√∂ller  
*4th workshop on analyzing and interpreting neural networks for NLP (collocated with EMNLP 2021)*  
[BlackboxNLP 2021 proceedings](https://aclanthology.org/2021.blackboxnlp-1.17/) | [arXiv](https://arxiv.org/abs/2103.15429) | [GitHub](https://github.com/DFKI-NLP/emp-exp)  

### Combining Open Domain Question Answering with a Task-Oriented Dialog System
Jan Nehring, **Nils Feldhus**, Harleen Kaur and Akhyar Ahmed  
*1st Workshop on Document-grounded Dialogue and Conversational Question Answering (DialDoc 2021)*  
[ACL Anthology](https://aclanthology.org/2021.dialdoc-1.5/)  

### European Language Grid: A Joint Platform for the European Language Technology Community
Georg Rehm et al.  
*16th Conference of the European Chapter of the Association for Computational Linguistics (EACL): System Demonstrations*  
[EACL 2021 Proceedings](https://aclanthology.org/2021.eacl-demos.26/)  


## 2020

### Evaluating German Transformer Language Models with Syntactic Agreement Tests
Karolina Zaczynska, **Nils Feldhus**\*, Robert Schwarzenberg, Aleksandra Gabryszak and Sebastian M√∂ller  
*5th Swiss Text Analytics Conference (SwissText) & 16th Conference on Natural Language Processing (KONVENS)*  
[SwissText/KONVENS 2020 Proceedings](http://ceur-ws.org/Vol-2624/) | [arXiv](https://arxiv.org/pdf/2007.03765.pdf) | [GitHub](https://github.com/dfki-nlp/gevalm)  
<sup>* joint first authorship</sup>

### Towards an Interoperable Ecosystem of AI and LT Platforms: A Roadmap for the Implementation of Different Levels of Interoperability
Georg Rehm et al.  
*1st International Workshop on Language Technology Platforms (c/w LREC 2020)*  
[IWLTP 2020 Proceedings](https://aclanthology.org/2020.iwltp-1.15/)  


# Education üë®‚Äçüéì
2021-2025 ‚Äì Computer Science, PhD, Technische Universit√§t Berlin. Supervised by Sebastian M√∂ller: "Generating and evaluating human-centric explanations of language models"  

2016-2020 ‚Äì Cognitive Systems: Language, Learning and Reasoning, MSc, University of Potsdam. Supervised by Manfred Stede: "Utilizing machine translation for bootstrapping abstractive text summarization".  

2013-2016 ‚Äì Computational Linguistics, BA, Heidelberg University. Supervised by Katja Markert: "An in-depth investigation on timeline summarization evaluation".  

# Jobs üë®‚Äçüíº
2021-ongoing ‚Äì Researcher/Software Engineer @ German Research Institute for Artificial Intelligence (DFKI), Berlin, [Speech and Language Technology](https://www.dfki.de/en/web/research/research-departments/speech-and-language-technology/) group.  
[XAINES - Explaining AI with Narratives](https://www.dfki.de/en/web/research/projects-and-publications/projects-overview/project/xaines) project, supervised by Sebastian M√∂ller.  

2020-2021 ‚Äì Researcher/Software Engineer @ German Research Institute for Artificial Intelligence (DFKI), Berlin, [Speech and Language Technology](https://www.dfki.de/en/web/research/research-departments/speech-and-language-technology/) group.  
[European Language Grid](https://live.european-language-grid.eu/) project, supervised by Georg Rehm.  

2014 ‚Äì Student assistant at the Institute for Computational Linguistics @ Heidelberg University  

# Supervision üë®‚Äç‚Äçüè´
Qianli Wang ‚Äì Interactive NLP model exploration through dialogue systems  
Maximilian Bleick ‚Äì Explaining Political Biases in LLMs  
Maximilian Dustin Nasert & Christopher Ebert ‚Äì Examining Self-Rationalizing LLMs


## Completed
Jo√£o Lucas Mendes de Lemos Lins ‚Äì Instructional explanations  

Sahil Chopra ‚Äì Rationale generation for dialogue-based explanations  

Konstantin Biskupski (with Eleftherios Avramidis) ‚Äì MSc thesis @ TU Berlin: Quality estimation of machine-translated texts with fine-grained classification of errors  

Kiran Rohra (with Philippe Thomas) ‚Äì MSc thesis @ TU Berlin: Comparative error analysis of biomedical image labelling and captioning models  

Ajay Madhavan Ravichandran (with Philippe Thomas) ‚Äì MSc thesis @ TU Berlin: Evaluating text quality of generated radiology reports  

Mika Rebensburg (with Tim Polzehl & Stefan Hillmann) - BSc thesis @ TU Berlin : Automatic Evaluation of Chatbot Dialogs Using Pre-Trained Language Models in the Customer Support Domain  

Konstantin Biskupski, Lea Junack & Janis Piskol (with Eleftherios Avramidis & Vivien Macketanz) ‚Äì MSc/BSc software project @ TU Berlin: Assessing the Quality of Machine-translated Text  

Daniel Fernau (with Tim Polzehl & Stefan Hillmann) ‚Äì MSc thesis @ TU Berlin: Towards Adaptive Conversational Agents: Fine-tuning Language-Models for User Classification to enhance Usability  

## Courses
2022-10 - 2023-03 : Explainability in Natural Language Processing @ TU Berlin. Topics: (1) Contrastive Explanations of Text Generation Models. (2) Explainable Fact Checking.  


# Invited Talks
2023-11-03 : NEC Labs Europe, Heidelberg ‚Äì Generating and Evaluating Human-Centric Explanations of Language Model Behavior  


# Reviews ‚≠ê
**EACL 2024**  
**EMNLP 2023** (Main conference & BlackboxNLP workshop)  
**ACL 2023** (Reality Check theme track & Interpretability track)  
**EACL 2023**  
**EMNLP 2022** (Interpretability, Interactivity and Analysis of Models track; BlackboxNLP 2022 workshop)  
**ACL Rolling Review** (2021 November ‚Äì ongoing)  
**ACL 2022** (+ Emergency Reviews)  

As secondary reviewer:  
NLDB 2022, BlackboxNLP 2021, EMNLP 2021, ACL 2021, NAACL 2021, WebConf 2021, IWLTP 2020, EMNLP 2020, ACL 2020


# Recommended
<a href="{{ site.url }}/recommended">Video tutorials and publications I recommend</a>


# Mail üì®
nils (dot) feldhus (at) dfki (dot) de  
feldhusnlp (at) gmail (dot) com  

# Links üåê
[DFKI Profile](https://www.dfki.de/en/web/about-us/employee/person/nife02)  
[GitHub](https://github.com/nfelnlp)  
[GitLab](https://gitlab.com/nfel)  
[Semantic Scholar](https://www.semanticscholar.org/author/Nils-Feldhus/1641658310)  
[Google Scholar](https://scholar.google.com/citations?user=nM50iv8AAAAJ)  
[OpenReview](https://openreview.net/profile?id=~Nils_Feldhus1)  
[Twitter](https://twitter.com/nfelnlp)  
[Mastodon (sigmoid.social)](https://sigmoid.social/@feldhus)  


# Tools I love to work with üß∞
[PyTorch](https://pytorch.org/), [Hugging Face](https://huggingface.co/) datasets + transformers and [Captum](https://captum.ai/) : My "Explainable NLP toolbox"  
[PyCharm](https://www.jetbrains.com/pycharm/) + [Atom](https://atom.io/) : Preferred editors for writing code  
[Obsidian.md](https://obsidian.md/) (+ [dataview](https://github.com/blacksmithgu/obsidian-dataview/)), [Zotero](https://www.zotero.org/) and [Semantic Scholar](https://www.semanticscholar.org/) (API) : Paper management  


# Leisure activities and other interests üéµ
Hosting two web radio shows where I mix ambient (Neptunian @ FRISKY Radio, since 2014) and atmospheric electronic music (Idolatry @ Proton Radio, since 2015). I've been producing mixes for Mixcloud since 2011. All of these are available on [helioscope.net](https://helioscope.net/).  
Cycling and hiking  
Nature photography  
